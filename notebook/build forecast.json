{
	"name": "build forecast",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "starterpool",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "112g",
			"driverCores": 16,
			"executorMemory": "112g",
			"executorCores": 16,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2"
			}
		},
		"metadata": {
			"saveOutput": true,
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/20e228e4-63c7-480a-a860-4b61e9623727/resourceGroups/EDU-US-DevPoc/providers/Microsoft.Synapse/workspaces/educsademo/bigDataPools/starterpool",
				"name": "starterpool",
				"type": "Spark",
				"endpoint": "https://educsademo.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/starterpool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "2.4",
				"nodeCount": 3,
				"cores": 16,
				"memory": 112,
				"extraHeader": null
			}
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"inputCollapsed": true
				},
				"source": [
					"import pip\n",
					"package_names=['tabulate'] \n",
					"pip.main(['install'] + package_names) "
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"import warnings\n",
					"warnings.filterwarnings('ignore')\n",
					"import re\n",
					"import sys\n",
					"import datetime\n",
					"from tabulate import tabulate\n",
					"import numpy as np\n",
					"#import IPython.display as display\n",
					"\n",
					"dates = []\n",
					"def dataframe():\n",
					"    JH_DATA_URL = 'https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
					"    #JH_DATA_URL = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
					"    df_main = pd.DataFrame(columns = ['Province/State', 'Country/Region', 'date',\n",
					"                                'Lat' , 'Long', 'Confirmed'])\n",
					"    \n",
					"    \n",
					"    today = pd.Timestamp('today')\n",
					"    today = '{:%m-%d-%Y}'.format(today)\n",
					"    \n",
					"    \n",
					"    dates = pd.date_range(start='3-10-2021', end=today, freq='d')\n",
					"    dates = pd.to_datetime(dates, format='%m-%d-%Y')\n",
					"    dates = dates.strftime('%m-%d-%Y').tolist()\n",
					"    \n",
					"    for date in dates:\n",
					"        fname = JH_DATA_URL + date + '.csv'\n",
					"        \n",
					"        try:\n",
					"            df = pd.read_csv(fname)\n",
					"        except:\n",
					"            continue\n",
					"        \n",
					"        d1 = datetime.datetime.strptime(date, \"%m-%d-%Y\")\n",
					"        d2 = datetime.datetime.strptime('3-22-2021', \"%m-%d-%Y\")\n",
					"        \n",
					"        if d1 < d2:\n",
					"            try:\n",
					"                df = df[df['Country/Region'] == 'US']\n",
					"                df['date'] = date\n",
					"                df = df.filter(['Province/State', 'Country/Region', 'date',\n",
					"                                'Lat' , 'Long', 'Confirmed'])\n",
					"                \n",
					"            except:\n",
					"                pass\n",
					"            \n",
					"        else:\n",
					"            try:\n",
					"                df = df[df['Country_Region'] == 'US']\n",
					"                df['date'] = date\n",
					"                df = df.filter(['Province_State', 'Country_Region', 'date', \n",
					"                                'Lat' , 'Long_', 'Confirmed'])\n",
					"                \n",
					"                df.columns = ['Province/State', 'Country/Region', 'date',\n",
					"                                'Lat' , 'Long', 'Confirmed']\n",
					"            except:\n",
					"                pass\n",
					"            \n",
					"        df_main = pd.concat([df_main, df])\n",
					"    \n",
					"    df_main['date'] = pd.to_datetime(df_main['date'])\n",
					"    df_main['date'] = df_main['date'].dt.strftime('%m/%d/%Y')\n",
					"\n",
					"    try:\n",
					"        df_main['date'] = df_main['date'].map(lambda x: x.rstrip('0'))\n",
					"        df_main['date'] = df_main['date'].map(lambda x: x.rstrip('2'))\n",
					"        df_main['date'] = df_main['date'].map(lambda x: x.lstrip('0'))\n",
					"    except:\n",
					"        pass\n",
					"\n",
					"    df_sums = df_main.groupby(['Province/State','date'])['Confirmed'].sum().reset_index()\n",
					"    \n",
					"    return df_sums, df_main, dates\n",
					"    \n",
					"\n",
					"df_sums, df_main, dates = dataframe()\n",
					"\n",
					"col_names = ['Province/State', 'Country/Region', 'Lat', 'Long']\n",
					"\n",
					"today = pd.Timestamp('today')\n",
					"today = '{:%m/%d/%Y}'.format(today)\n",
					"dates = pd.date_range(start='3/10/2021', end=today, freq='d')\n",
					"dates = pd.to_datetime(dates, format='%m/%d/%Y')\n",
					"dates = dates.strftime('%m/%d/%Y')\n",
					"\n",
					"dates = dates.map(lambda x: x.rstrip('0'))\n",
					"dates = dates.map(lambda x: x.rstrip('2'))\n",
					"dates = dates.map(lambda x: x.lstrip('0'))\n",
					"\n",
					"\n",
					"\n",
					"col_names.extend(dates)\n",
					"\n",
					"provstates = list(set(df_sums['Province/State']))\n",
					"\n",
					"lofl = []\n",
					"for ps in provstates:\n",
					"    st_df = df_main[df_main['Province/State'].str.contains(ps)]\n",
					"    lat = st_df['Lat'].iloc[-1]\n",
					"    long = st_df['Long'].iloc[-1]\n",
					"    \n",
					"    ps_ls = [ps, 'US', lat, long]\n",
					"    cases = df_sums[df_sums['Province/State'].str.contains(ps)]\n",
					"    st_cases = cases['Confirmed'].tolist()\n",
					"    st_dates = cases['date'].tolist()\n",
					"    \n",
					"    c = []\n",
					"    for date in dates:\n",
					"        try:\n",
					"            ii = st_dates.index(date)\n",
					"            c.append(st_cases[ii])\n",
					"        except:\n",
					"            c.append(0)\n",
					"\n",
					"    ps_ls.extend(c)\n",
					"    lofl.append(ps_ls)\n",
					"\n",
					"\n",
					"\n",
					"df = pd.DataFrame.from_records(lofl, columns=col_names)"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import lit, col, round\n",
					"from pyspark.sql.types import StructType, StructField, StringType, DoubleType, DateType\n",
					"\n",
					"from scipy.stats import binom\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"import datetime\n",
					"\n",
					"import re\n",
					"import warnings\n",
					"import sys\n",
					"from scipy.optimize import curve_fit\n",
					"from scipy import stats\n",
					"\n",
					"import base64\n",
					"warnings.filterwarnings('ignore')"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"def obs_pred_rsquare(obs, pred):\n",
					"    # Determines the prop of variability in a data set accounted for by a model\n",
					"    # In other words, this determines the proportion of variation explained by\n",
					"    # the 1:1 line in an observed-predicted plot.\n",
					"    return 1 - sum((obs - pred) ** 2) / sum((obs - np.mean(obs)) ** 2)"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"def obs_pred_rsquare(obs, pred):\n",
					"    # Determines the prop of variability in a data set accounted for by a model\n",
					"    # In other words, this determines the proportion of variation explained by\n",
					"    # the 1:1 line in an observed-predicted plot.\n",
					"    return 1 - sum((obs - pred) ** 2) / sum((obs - np.mean(obs)) ** 2)\n",
					"\n",
					"################ Simple growth-based statistical models\n",
					"\n",
					"def logistic(x, a, b, c):\n",
					"    # A general logistic function\n",
					"    # x is observed data\n",
					"    # a, b, c are optimized by scipy optimize curve fit\n",
					"    return a / (np.exp(-c * x) + b)\n",
					"\n",
					"\n",
					"def get_logistic(obs_x, obs_y, ForecastDays):\n",
					"    # obs_x: observed x values\n",
					"    # obs_y: observd y values\n",
					"    # ForecastDays: number of days ahead to extend prediction\n",
					"    \n",
					"    # convert obs_x to numpy array\n",
					"    obs_x = np.array(obs_x) \n",
					"    # In fitting this model, assume that trailing zeros in obs_y data \n",
					"    # are not real but instead represent a lack of information\n",
					"    # Otherwise, the logistic model will fail to fit\n",
					"    for i, val in enumerate(obs_y):\n",
					"        if val == 0:\n",
					"            try:\n",
					"                obs_y[i] = obs_y[i-1]\n",
					"            except:\n",
					"                pass\n",
					"    # convert obs_y to numpy array\n",
					"    obs_y = np.array(obs_y)   \n",
					"    try:\n",
					"        # attempt to fit the logistic model to the observed data\n",
					"        # popt: optimized model parameter values\n",
					"        popt, pcov = curve_fit(logistic, obs_x, obs_y)\n",
					"        # get predicted y values\n",
					"        pred_y = logistic(obs_x, *popt)\n",
					"        # extend x values by number of ForecastDays\n",
					"        forecasted_x = np.array(list(range(max(obs_x) + ForecastDays)))\n",
					"        # get corresponding forecasted y values, i.e., extend the predictions\n",
					"        forecasted_y = logistic(forecasted_x, *popt)\n",
					"        \n",
					"        # prevent use of negative y values and\n",
					"        # trailing zero-valued y values\n",
					"        for i, val in enumerate(forecasted_y):\n",
					"            if val <= 0:\n",
					"                try:\n",
					"                    obs_y[i] = obs_y[i-1]\n",
					"                except:\n",
					"                    pass\n",
					"        # if the minimum y value is still less than zero\n",
					"        # then use the polynomial model\n",
					"        if np.min(forecasted_y) < 0:\n",
					"            forecasted_y, forecasted_x, pred_y = get_polynomial(obs_x, obs_y, ForecastDays)\n",
					"    except:\n",
					"        # if the logistic model totally fails to fit\n",
					"        # then use the polynomial model\n",
					"        forecasted_y, forecasted_x, pred_y = get_polynomial(obs_x, obs_y, ForecastDays)\n",
					"    \n",
					"    # return the forecasted x-y values and predicted y values\n",
					"    return forecasted_y, forecasted_x, pred_y\n",
					"\n",
					"\n",
					"def get_exponential(obs_x, obs_y, ForecastDays):\n",
					"    # obs_x: observed x values\n",
					"    # obs_y: observd y values\n",
					"    # ForecastDays: number of days ahead to extend prediction\n",
					"    \n",
					"    # convert obs_x to numpy array\n",
					"    obs_x = np.array(obs_x)   \n",
					"    # In fitting this model, assume that trailing zeros in obs_y data \n",
					"    # are not real but instead represent a lack of information\n",
					"    # Otherwise, the logistic model will fail to fit\n",
					"    for i, val in enumerate(obs_y):\n",
					"        if val == 0:\n",
					"            try:\n",
					"                obs_y[i] = obs_y[i-1]\n",
					"            except:\n",
					"                pass       \n",
					"    \n",
					"    # use linear regression to obtain the estimated parameters for\n",
					"    # an exponential fit. This is not an optimization procedure,\n",
					"    # but should not fail to provide a best fit line\n",
					"    slope, intercept, r_value, p_value, std_err = stats.linregress(obs_x, np.log(obs_y))\n",
					"    # convert obs_y to numpy array\n",
					"    obs_y = np.array(obs_y)\n",
					"    \n",
					"    # get predicted y values\n",
					"    pred_y = np.exp(intercept + slope*obs_x)\n",
					"    # extend x values by number of ForecastDays\n",
					"    forecasted_x = np.array(list(range(max(obs_x) + ForecastDays)))\n",
					"    # get corresponding forecasted y values, i.e., extend the predictions\n",
					"    forecasted_y = np.exp(intercept + slope*forecasted_x)\n",
					"    \n",
					"    # return the forecasted x-y values and predicted y values\n",
					"    return forecasted_y, forecasted_x, pred_y\n",
					"        \n",
					"\n",
					"\n",
					"def get_polynomial(obs_x, obs_y, ForecastDays):\n",
					"    # obs_x: observed x values\n",
					"    # obs_y: observd y values\n",
					"    # ForecastDays: number of days ahead to extend prediction\n",
					"    \n",
					"    # convert obs_x to numpy array\n",
					"    obs_x = np.array(obs_x)  \n",
					"    # In fitting this model, assume that trailing zeros in obs_y data \n",
					"    # are not real but instead represent a lack of information\n",
					"    # Otherwise, the logistic model will fail to fit\n",
					"    for i, val in enumerate(obs_y):\n",
					"        if val == 0:\n",
					"            try:\n",
					"                obs_y[i] = obs_y[i-1]\n",
					"            except:\n",
					"                pass       \n",
					"    \n",
					"    # convert obs_y to numpy array\n",
					"    obs_y = np.array(obs_y)\n",
					"    \n",
					"    try:\n",
					"        # attempt to fit the polynomial model to the observed data\n",
					"        # z: best-fit model parameter values\n",
					"        z = np.polyfit(obs_x, obs_y, 2)\n",
					"        # p: one-dimensional polynomial class; constructs the polynomial\n",
					"        p = np.poly1d(z)\n",
					"        # get predicted y values\n",
					"        pred_y = p(obs_x)\n",
					"        \n",
					"        # extend x values by number of ForecastDays\n",
					"        forecasted_x = np.array(list(range(max(obs_x) + ForecastDays)))\n",
					"        # get corresponding forecasted y values, i.e., extend the predictions\n",
					"        forecasted_y = p(forecasted_x)\n",
					"    except:   #Exception as e:\n",
					"        # if the polynomial model fails, the lack of a substitute here\n",
					"        # will throw an error\n",
					"        pass\n",
					"    \n",
					"    # return the forecasted x-y values and predicted y values\n",
					"    return forecasted_y, forecasted_x, pred_y\n",
					"\n",
					"def fit_curve(obs_x, obs_y, model, ForecastDays, N, ArrivalDate):\n",
					"    # A function to fit various models to observed COVID-19 cases data according to:\n",
					"    # obs_x: observed x values\n",
					"    # obs_y: observed y values\n",
					"    # model: the model to fit\n",
					"    # ForecastDays: number of days ahead to extend predictions\n",
					"    # N: population size of interest\n",
					"    # T0: likely data of first infection (used by SEIR-SD model)\n",
					"    # incubation_period: disease-specific epidemilogical parameter\n",
					"        # average number of days until an exposed person becomes\n",
					"        # begins to exhibit symptoms of infection\n",
					"    # infectious_period: disease-specific epidemilogical parameter\n",
					"        # average number of days an infected person is infected\n",
					"    # rho: disease-specific epidemilogical parameter\n",
					"        # aka basic reproductive number\n",
					"        # average number of secondary infections produced by a typical case \n",
					"        # of an infection in a population where everyone is susceptible\n",
					"    # socdist: population-specific social-distancing parameter\n",
					"        # \n",
					"    \n",
					"    # use the number of y observations as the number of x observations\n",
					"    obs_x = list(range(len(obs_y)))\n",
					"    # convert y and x observations to numpy arrays\n",
					"    obs_x = np.array(obs_x)\n",
					"    obs_y = np.array(obs_y)\n",
					"    \n",
					"    # Get the forecasted values, predicted values, and observed vs predicted r-square\n",
					"    # value for the chosen model\n",
					"    if model == 'logistic':\n",
					"        forecasted_y, forecasted_x, pred_y = get_logistic(obs_x, obs_y, ForecastDays)\n",
					"        obs_pred_r2 = obs_pred_rsquare(obs_y, pred_y)\n",
					"      \n",
					"    elif model == 'exponential':\n",
					"        forecasted_y, forecasted_x, pred_y = get_exponential(obs_x, obs_y, ForecastDays)\n",
					"        obs_pred_r2 = obs_pred_rsquare(obs_y, pred_y)\n",
					"        \n",
					"    elif model == 'polynomial':\n",
					"        forecasted_y, forecasted_x, pred_y = get_polynomial(obs_x, obs_y, ForecastDays)\n",
					"        obs_pred_r2 = obs_pred_rsquare(obs_y, pred_y)\n",
					"       \n",
					"    elif model == 'SEIR-SD (Requires <1 minute to optimize)':        \n",
					"        forecasted_y, forecasted_x, pred_y = get_seir(obs_x, obs_y, ForecastDays, N)\n",
					"        obs_pred_r2 = obs_pred_rsquare(obs_y, pred_y)\n",
					"        \n",
					"    # return the r-square and observed, predicted, and forecasted values\n",
					"    return obs_pred_r2, obs_x, pred_y, forecasted_x, forecasted_y\n",
					"\n",
					"\n",
					"def get_seir(obs_x, obs_y, ForecastDays, N):\n",
					"    \n",
					"    \n",
					"    def correct_beta(sd, beta, fraction_infected):\n",
					"        # A function to adjust the contact rate (beta) by the percent infected\n",
					"        \n",
					"        pi = fraction_infected\n",
					"        beta = beta/(sd*pi + 1)\n",
					"        \n",
					"        return beta\n",
					"\n",
					"\n",
					"\n",
					"    def test_effect(i):\n",
					"        # A logistic function with an output ranging between 0 and 1 \n",
					"        # 'i' is the time step\n",
					"        # This function corrects the apparent number of infected \n",
					"        # according to an assumption that testing for COVID-19 was\n",
					"        # minimal in the first few weeks of infection\n",
					"        \n",
					"        return 1/(1+np.exp(-0.1*i+5.8))\n",
					"    \n",
					"    \n",
					"    def seir(obs_pred_r2x, alpha, beta, gamma, t_max, sd, fdays=0):\n",
					"        \n",
					"        t_max += fdays\n",
					"        t = list(range(int(t_max))) \n",
					"        \n",
					"        # unpack initial values\n",
					"        S = [1 - 1/N] # fraction susceptible\n",
					"        E = [1/N] # fraction exposed\n",
					"        I = [0] # fraction infected\n",
					"        R = [0] # fraction recovered\n",
					"        \n",
					"        # declare a list that will hold testing-corrected\n",
					"        # number of infections\n",
					"        Ir = list(I)\n",
					"        \n",
					"        # loop through time steps from date of first likely infection\n",
					"        \n",
					"        # to end of forecast window\n",
					"        \n",
					"        for i in t[1:]:\n",
					"            \n",
					"            #print('hi', t_max, alpha, beta, gamma)\n",
					"            \n",
					"            # fraction infected is the last element in the I list\n",
					"    \n",
					"            # adjust the contact rate (beta) by the % infected\n",
					"            beta = correct_beta(sd, beta, I[-1])\n",
					"            \n",
					"            # No. susceptible at time t = S - beta*S*I\n",
					"            next_S = S[-1] - beta *S[-1]*I[-1]\n",
					"            \n",
					"            # No. exposed at time t = S - beta*S*I - alpha*E\n",
					"            next_E = E[-1] + beta *S[-1]*I[-1] - alpha*E[-1]\n",
					"            \n",
					"            # No. infected at time t = I + alpha*E - gamma*I\n",
					"            next_I = I[-1] + alpha*E[-1] - gamma*I[-1] #* 0.1\n",
					"            \n",
					"            # No. recovered at time t = R - gamma*I\n",
					"            next_R = R[-1] + (gamma*I[-1])\n",
					"            \n",
					"            S.append(next_S)\n",
					"            E.append(next_E)\n",
					"            I.append(next_I)\n",
					"            R.append(next_R)\n",
					"            \n",
					"            # get the testing lag\n",
					"            test_lag = test_effect(i)\n",
					"            # get apparent infected by multiplying I by the testing lag\n",
					"            Ir.append(next_I * test_lag)\n",
					"        \n",
					"        # multiply array of apparent percent infected by N\n",
					"        I = np.array(Ir)*N\n",
					"        # convert I to a list\n",
					"        I = I.tolist()\n",
					"        \n",
					"        # number of observed days + size of forecast window\n",
					"        num = len(obs_x)+fdays\n",
					"        \n",
					"        # trim extra days, i.e., between T0 and day of first observation\n",
					"        I = I[-num:]\n",
					"        I = np.array(I)\n",
					"        \n",
					"        return I\n",
					"\n",
					"\n",
					"\n",
					"    forecasted_y, forecasted_x, pred_y = [], [], []\n",
					"    \n",
					"    today = pd.to_datetime('today', format='%Y/%m/%d')\n",
					"    \n",
					"    sd_o = 0\n",
					"    pred_y_o = []\n",
					"    \n",
					"    r2_o = 0\n",
					"    alpha_o = 0\n",
					"    beta_o = 0\n",
					"    gamma_o = 0\n",
					"    t_max_o = 0\n",
					"    sd_o = 0\n",
					"    \n",
					"    for i in range(20000):\n",
					"        \n",
					"        incubation_period = np.random.uniform(4, 6)\n",
					"        infectious_period = np.random.uniform(4, 10)\n",
					"        rho = np.random.uniform(1, 6)\n",
					"        sd = np.random.uniform(0, 100)\n",
					"        d1 = np.random.randint(1, 60)\n",
					"        \n",
					"        ArrivalDate = today - datetime.timedelta(days = d1 + len(obs_x))\n",
					"        t_max = (today - ArrivalDate).days\n",
					"        \n",
					"        alpha = 1/incubation_period \n",
					"        gamma = 1/infectious_period\n",
					"        beta = rho*gamma\n",
					"\n",
					"        pred_y = seir(obs_x, alpha, beta, gamma, t_max, sd)\n",
					"        \n",
					"        obs_pred_r2 = obs_pred_rsquare(obs_y, pred_y)\n",
					"        \n",
					"        if obs_pred_r2 > r2_o:\n",
					"            \n",
					"            alpha_o = float(alpha)\n",
					"            beta_o = float(beta)\n",
					"            gamma_o = float(gamma)\n",
					"            t_max_o = float(t_max)\n",
					"            sd_o = float(sd)\n",
					"            \n",
					"            r2_o = float(obs_pred_r2)\n",
					"            \n",
					"            pred_y_o = pred_y\n",
					"    \n",
					"    \n",
					"    forecasted_y = seir(obs_x, alpha_o, beta_o, gamma_o, t_max_o, sd_o, ForecastDays-1)\n",
					"    forecasted_x = list(range(len(forecasted_y)))\n",
					"    \n",
					"    # return the forecasted x-y values and predicted y values\n",
					"    return forecasted_y, forecasted_x, pred_y_o"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"def f(df_sub, model,forecastDays,PopSize,ArrivalDate,incubation_period,infectious_period, rho, socdist, T0, N_mod):\n",
					"      \n",
					"  ForecastDays = int(forecastDays)+int(1) \n",
					"\n",
					"\n",
					"  df_sub = df_sub.loc[:, (df_sub != 0).any(axis=0)]\n",
					"  yi = list(df_sub)\n",
					" \n",
					"  \n",
					"  for i, j in enumerate([-4,-3,-2,-1, 0]):\n",
					"    if j == 0:\n",
					"      DATES = yi[6:]\n",
					"      focal = df_sub.iloc[0,6:].values\n",
					"    else:\n",
					"      DATES = yi[6:j]\n",
					"      focal = df_sub.iloc[0,6:j].values\n",
					"    \n",
					"    \n",
					"    y = []\n",
					"    dates = []\n",
					"    for ii, val in enumerate(focal):\n",
					"      if len(y) > 0 or val > 0:\n",
					"        y.append(val)\n",
					"        dates.append(DATES[ii])\n",
					"   \n",
					"    x = list(range(len(y)))   \n",
					"    \n",
					"                                                                              \n",
					"    obs_pred_r2_G,   obs_x,    pred_y, forecasted_x, forecasted_y = fit_curve(x, y, model,  ForecastDays, PopSize, ArrivalDate)\n",
					"    obs_y_G = np.array(list(y))\n",
					"   \n",
					"\n",
					"    if obs_pred_r2_G < 0:\n",
					"      obs_pred_r2_G = 0.0\n",
					"\n",
					"    y = np.array(y)\n",
					"    y[y < 0] = 0\n",
					"    pred_y_G = np.array(pred_y)\n",
					"    pred_y_G[pred_y_G < 0] = 0\n",
					"\n",
					"    forecasted_y = np.array(forecasted_y)\n",
					"    forecasted_y[forecasted_y < 0] = 0\n",
					"    forecast_vals = np.copy(forecasted_y)\n",
					"\n",
					"    numdays = len(forecasted_x)\n",
					"    latest_date = pd.to_datetime(dates[-1])\n",
					"    first_date = pd.to_datetime(dates[0])    \n",
					"    \n",
					"    future_date = latest_date + datetime.timedelta(days = ForecastDays-1)\n",
					"    fdates = pd.date_range(start=first_date, end=future_date)\n",
					"    fdates = fdates.strftime('%m/%d/%Y')\n",
					"\t    \n",
					"\t\n",
					"    latest_date = pd.to_datetime(dates[-1])\n",
					"    first_date = pd.to_datetime(dates[0])\n",
					"    dates = pd.date_range(start=first_date, end=latest_date)\n",
					"    dates = dates.strftime('%m/%d')\n",
					"\n",
					"  \n",
					"  forecast_vals = forecast_vals.tolist()\n",
					"  \n",
					"  fdates = fdates.tolist() \n",
					"  #fdates = fdates[-(ForecastDays+1):] \n",
					"  #forecast_vals = forecast_vals[-(ForecastDays+1):]\n",
					"  \n",
					"  return(fdates, forecast_vals, obs_pred_r2_G)"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"models = [\"logistic\", \"exponential\", \"polynomial\"]\n",
					"#models = [\"exponential\"]\n",
					"\n",
					"#df_filtered = df[(df['Country/Region'] == 'China') ]\n",
					"df_filtered = df[(df['Country/Region'] == 'US') & (df['Province/State'] != 'US')]\n",
					"#df_filtered = df\n",
					"#df_filtered = df[(df['Province/State'] == 'New York')]"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"locations = df_filtered[['Country/Region', 'Province/State']]\n",
					"locations = locations.replace(np.nan, 'NA', regex=True)\n",
					"locations = locations.values.tolist()"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"schema = StructType([\n",
					"    StructField(\"fdates\", DateType()),\n",
					"    StructField(\"forecast_vals\", DoubleType()),\n",
					"    StructField(\"CountryRegion\", StringType()),\n",
					"    StructField(\"ProvinceState\", StringType()),\n",
					"    StructField(\"model\", StringType()),\n",
					"    StructField(\"obs_pred_r2_G\", DoubleType())    \n",
					"])\n",
					"appended = sqlContext.createDataFrame(sc.emptyRDD(), schema)"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"#paramenters for social distancing - the model has not been implemented\n",
					"ArrivalDate = '03/22/2021'\n",
					"incubation_period = 14\n",
					"infectious_period = 14\n",
					"rho = 8\n",
					"socdist = 75\n",
					"T0=2\n",
					"N_mod=1\n",
					"PopSize =12671821"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"for CountryRegion, ProvinceState in locations:\n",
					"  for model in models:   \n",
					"    df_sub = df_filtered[(df_filtered['Country/Region'] == CountryRegion) & (df_filtered['Province/State'] == ProvinceState)]     \n",
					"    try:            \n",
					"      fdates, forecast_vals, obs_pred_r2_G = f(df_sub, model, 10,PopSize,ArrivalDate,incubation_period,infectious_period, rho, socdist, T0, N_mod)       \n",
					"      appended = appended.union(\n",
					"        spark.createDataFrame(list(zip(fdates, forecast_vals)), [\"fdates\", \"forecast_vals\"])\n",
					"        .withColumn(\"forecast_vals\", round(col(\"forecast_vals\")))\n",
					"        .withColumn(\"CountryRegion\", lit(CountryRegion))\n",
					"        .withColumn(\"ProvinceState\", lit(ProvinceState))\n",
					"        .withColumn(\"model\", lit(model))\n",
					"        .withColumn(\"obs_pred_r2_G\", round(lit(obs_pred_r2_G), 2))\n",
					"      )\n",
					"    except:   \n",
					"      pass\n",
					"#display(appended)    \n",
					"#display(\n",
					"#  appended\n",
					"#  .groupBy(\"CountryRegion\", \"ProvinceState\", \"model\", \"obs_pred_r2_G\").pivot(\"fdates\").sum(\"forecast_vals\")\n",
					"#  .sort(\"CountryRegion\", \"ProvinceState\", \"model\")\n",
					"#)"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"diagram": {
						"activateDiagramType": 1,
						"chartConfig": {
							"category": "bar",
							"keys": [
								"fdates"
							],
							"values": [
								"forecast_vals"
							],
							"yLabel": "forecast_vals",
							"xLabel": "fdates",
							"aggregation": "SUM",
							"aggByBackend": false
						},
						"aggData": "{\"forecast_vals\":{\"03/12/2020\":3045,\"03/13/2020\":3568,\"03/14/2020\":3743,\"03/15/2020\":3927,\"03/16/2020\":4121,\"03/17/2020\":4326,\"03/18/2020\":4562,\"03/19/2020\":4936,\"03/20/2020\":5320,\"03/21/2020\":5723,\"03/22/2020\":6134,\"03/23/2020\":6562,\"03/24/2020\":7007,\"03/25/2020\":7504,\"03/26/2020\":8124,\"03/27/2020\":8759,\"03/28/2020\":9415,\"03/29/2020\":10089,\"03/30/2020\":10783,\"03/31/2020\":11497,\"04/01/2020\":12232,\"04/02/2020\":12992,\"04/03/2020\":13774,\"04/04/2020\":14583,\"04/05/2020\":15416,\"04/06/2020\":16276,\"04/07/2020\":17167,\"04/08/2020\":18086,\"04/09/2020\":19037,\"04/10/2020\":20018,\"04/11/2020\":21034,\"04/12/2020\":22083,\"04/13/2020\":23171,\"04/14/2020\":24295,\"04/15/2020\":25458,\"04/16/2020\":26664,\"04/17/2020\":27908,\"04/18/2020\":29198,\"04/19/2020\":30530,\"04/20/2020\":31911,\"04/21/2020\":33337,\"04/22/2020\":34812,\"04/23/2020\":36339,\"04/24/2020\":37917,\"04/25/2020\":39548,\"04/26/2020\":41230,\"04/27/2020\":42971,\"04/28/2020\":44767,\"04/29/2020\":46620,\"04/30/2020\":48532,\"05/01/2020\":50505,\"05/02/2020\":52537,\"05/03/2020\":54631,\"05/04/2020\":56786,\"05/05/2020\":59007,\"05/06/2020\":61290,\"05/07/2020\":63637,\"05/08/2020\":66050,\"05/09/2020\":68530,\"05/10/2020\":71078,\"05/11/2020\":73691,\"05/12/2020\":76373,\"05/13/2020\":79125,\"05/14/2020\":81945,\"05/15/2020\":84837,\"05/16/2020\":87802,\"05/17/2020\":90839,\"05/18/2020\":93953,\"05/19/2020\":97142,\"05/20/2020\":100409,\"05/21/2020\":103754,\"05/22/2020\":107181,\"05/23/2020\":110693,\"05/24/2020\":114293,\"05/25/2020\":117982,\"05/26/2020\":121764,\"05/27/2020\":125645,\"05/28/2020\":129627,\"05/29/2020\":133713,\"05/30/2020\":137913,\"05/31/2020\":142229,\"06/01/2020\":146668,\"06/02/2020\":151236,\"06/03/2020\":155942,\"06/04/2020\":160792,\"06/05/2020\":165792,\"06/06/2020\":170956,\"06/07/2020\":176292,\"06/08/2020\":181810,\"06/09/2020\":187520,\"06/10/2020\":193433,\"06/11/2020\":199563,\"06/12/2020\":205924,\"06/13/2020\":212529,\"06/14/2020\":219396,\"06/15/2020\":226533,\"06/16/2020\":233965,\"06/17/2020\":241707,\"06/18/2020\":249779,\"06/19/2020\":258197,\"06/20/2020\":266984,\"06/21/2020\":174366,\"06/22/2020\":178240,\"06/23/2020\":182229,\"06/24/2020\":186347,\"06/25/2020\":190597,\"06/26/2020\":194990,\"06/27/2020\":199534,\"06/28/2020\":204239,\"06/29/2020\":209115,\"06/30/2020\":214173,\"07/01/2020\":219422,\"07/02/2020\":224875,\"07/03/2020\":230544,\"07/04/2020\":236443,\"07/05/2020\":242581,\"07/06/2020\":248976,\"07/07/2020\":255637,\"07/08/2020\":262586,\"07/09/2020\":269834,\"07/10/2020\":277397,\"07/11/2020\":285297,\"07/12/2020\":293548,\"07/13/2020\":302169,\"07/14/2020\":311185,\"07/15/2020\":320611,\"07/16/2020\":330475,\"07/17/2020\":340791,\"07/18/2020\":351592}}",
						"isSummary": false,
						"previewData": {
							"filter": null
						},
						"isSql": false
					}
				},
				"source": [
					"#display(appended)\n",
					"#display(\n",
					"#  appended\n",
					"#  .groupBy(\"CountryRegion\", \"ProvinceState\", \"model\", \"obs_pred_r2_G\").pivot(\"fdates\").sum(\"forecast_vals\")\n",
					"#  .sort(\"CountryRegion\", \"ProvinceState\", \"model\")\n",
					"#)"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"appended.write.format(\"jdbc\").option(\"mode\",\"SaveMode.Overwrite\").option(\"url\", \"jdbc:sqlserver://covidsql19.database.windows.net:1433\").option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\").option(\"database\",\"CovID19Forecasts\").option(\"dbtable\", \"CovId19Staging\").option(\"user\", \"mainuser\").option(\"password\", \"#Welcome2018#\").save()  "
				],
				"attachments": null,
				"execution_count": null
			}
		]
	}
}